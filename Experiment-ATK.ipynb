{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright &copy; 2024 Praneeth Vadlapati"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup:\n",
    "\n",
    "Example of .env: \n",
    "```bash\n",
    "# Groq API to use LLMs - https://console.groq.com/keys\n",
    "# Groq is preferred for fast responses\n",
    "LM_PROVIDER_BASE_URL=https://api.groq.com/openai/v1\n",
    "LM_API_KEY=\n",
    "LM_MODEL=llama-3.1-70b-versatile\n",
    "\n",
    "# For Google Trends API - https://serpapi.com/manage-api-key\n",
    "SERP_API_KEY=\n",
    "```\n",
    "\n",
    "Installing packages:\n",
    "```bash\n",
    "pip install openai python-dotenv google-search-results markdown2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading a Language Model, adding the page content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content file: data/Language-Model-Learning-a-Dataset-for-Data-Augmented-Prediction.md\n",
      "Model: llama-3.1-70b-versatile\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Page title: **Introducing LML-DAP: A New Way to Combine Language Models with Data for Better Predictions**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Machine learning (ML) models are powerful, but they often lack transparency. They make predictions, but the reasoning behind them can be a mystery. ML models need a lot of pre-processing before they can work with data. But what if there was a faster, more explainable method for predictions?\n",
       "\n",
       "**LML-DAP** (*Language Model Learning a Dataset for Data-Augmented Prediction*), offers an exciting alternative. Instead of relying on standard ML techniques, this method uses **Large Language Models (LLMs)*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import markdown2\n",
    "import pandas as pd\n",
    "from serpapi import SerpApiClient\n",
    "\n",
    "from common_functions import get_lm_response, extract_data, \\\n",
    "    print_progress, print_error, model, data_folder, display_md, load_env\n",
    "\n",
    "trends_engine = 'google_trends'\n",
    "\n",
    "# User inputs\n",
    "topic = 'Language Model Learning a Dataset for Data-Augmented Prediction'\n",
    "topic_for_url = topic.replace(' ', '-')\n",
    "\n",
    "content_file = os.path.join(data_folder, f'{topic_for_url}.md')\n",
    "metadata_file = os.path.join(data_folder, f'{topic_for_url}.json')\n",
    "\n",
    "print(f'Content file: {content_file}')\n",
    "print(f'Model: {model}')\n",
    "\n",
    "# try to read from file\n",
    "page_content = None\n",
    "if os.path.exists(content_file):\n",
    "\twith open(content_file, 'r') as f:\n",
    "\t\tpage_content = f.read().strip() or None\n",
    "\n",
    "if not page_content:\n",
    "\tprint('-'*7)\n",
    "\tprint('No content found for this topic. Please add content in markdown to the file.')\n",
    "\tprint(f'File: {content_file}')\n",
    "\traise SystemExit\n",
    "\n",
    "page_title = page_content.split('\\n')[0].strip()\n",
    "page_title = page_title.strip('#').strip().strip('*').strip()\n",
    "page_content = page_content.split('\\n', 1)[1].strip()  # remove first line\n",
    "\n",
    "display_md(f'Page title: **{page_title}**')\n",
    "display_md(page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generating keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate keywords related to the page and content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 10 keywords:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['machine learning',\n",
       " 'language models',\n",
       " 'explainable predictions',\n",
       " 'data-augmented prediction',\n",
       " 'transparent AI']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword_gen_prompt_template = '''\n",
    "Page content:\n",
    "{page_content}\n",
    "---\n",
    "Page title: {page_title}\n",
    "\n",
    "Generate 10 SEO keywords for the above page based on the page content.\n",
    "\n",
    "All keywords must be in the same language as the page title and content.\n",
    "Respond with a list of keywords separated by commas, inside tags like this:\n",
    "Sample response: \n",
    "<keywords>\n",
    "\tkeyword1, keyword2, keyword3\n",
    "</keywords>\n",
    "'''.strip()\n",
    "\n",
    "keyword_gen_prompt = keyword_gen_prompt_template.format(\n",
    "    page_title=page_title, page_content=page_content)\n",
    "keyword_gen_response = get_lm_response(keyword_gen_prompt)\n",
    "keywords = extract_data(keyword_gen_response, tag='keywords')\n",
    "# load keywords to array\n",
    "keywords = keywords.split(',')\n",
    "keywords = [keyword.strip() for keyword in keywords]\n",
    "\n",
    "print(f'Generated {len(keywords)} keywords:')\n",
    "keywords[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate keywords that are not directly similar, but related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 5 similar keywords:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Explainable AI',\n",
       " 'Natural Language Processing Applications',\n",
       " 'Transparent Machine Learning',\n",
       " 'Interpretable Predictive Models',\n",
       " 'Data-Driven Decision Making']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_keys_prompt_template = '''\n",
    "Page content:\n",
    "{page_content}\n",
    "---\n",
    "Page title: {page_title}\n",
    "Find 5 related topics to the above page.\n",
    "\n",
    "Respond with a list of SEO keywords separated by commas, inside tags like this:\n",
    "Sample response: \n",
    "<keywords>\n",
    "\tkeyword1, keyword2, keyword3\n",
    "</keywords>\n",
    "\n",
    "All keywords must be in the same language as the page title and content.\n",
    "Keywords should not be directly related to the content, but\n",
    "should be related to the topic.\n",
    "'''.strip()\n",
    "\n",
    "similar_keys_prompt = similar_keys_prompt_template.format(\n",
    "    page_title=page_title, page_content=page_content)\n",
    "similar_keys_response = get_lm_response(similar_keys_prompt)\n",
    "similar_keys_keywords = extract_data(similar_keys_response, tag='keywords')\n",
    "similar_keys_keywords = similar_keys_keywords.split(',')\n",
    "similar_keys_keywords = [keyword.strip() for keyword in similar_keys_keywords]\n",
    "print(f'Generated {len(similar_keys_keywords)} similar keywords:')\n",
    "similar_keys_keywords = similar_keys_keywords[:5]\n",
    "similar_keys_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final 15 keywords:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['machine learning',\n",
       " 'language models',\n",
       " 'explainable predictions',\n",
       " 'data-augmented prediction',\n",
       " 'transparent ai']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords.extend(similar_keys_keywords)  # add similar keywords\n",
    "if page_title not in keywords:\n",
    "\tkeywords.insert(0, page_title)\n",
    "keywords = [keyword.lower() for keyword in keywords]\n",
    "\n",
    "for keyword in keywords:\n",
    "\t# remove duplicates without disturbing the order\n",
    "\twhile keywords.count(keyword) > 1:\n",
    "\t\t# remove from last\n",
    "\t\tlast_index_of_word = (len(keywords) - 1) - keywords[::-1].index(keyword)\n",
    "\t\tkeywords.pop(last_index_of_word)\n",
    "\tif len(keyword) > 60:  # remove long keywords\n",
    "\t\tkeywords.remove(keyword)\n",
    "\n",
    "print(f'Final {len(keywords)} keywords:')\n",
    "keywords[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fetching trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..!!..!.....!!."
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Oldest_Value</th>\n",
       "      <th>Latest_Value</th>\n",
       "      <th>Growth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explainable ai</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>8800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>transparent ai</td>\n",
       "      <td>46</td>\n",
       "      <td>84</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>machine learning</td>\n",
       "      <td>53</td>\n",
       "      <td>71</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>large language models</td>\n",
       "      <td>37</td>\n",
       "      <td>70</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>language models</td>\n",
       "      <td>43</td>\n",
       "      <td>67</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dataset analysis</td>\n",
       "      <td>42</td>\n",
       "      <td>51</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Keyword  Oldest_Value  Latest_Value  Growth\n",
       "0         explainable ai             1            89    8800\n",
       "1         transparent ai            46            84      83\n",
       "2       machine learning            53            71      34\n",
       "3  large language models            37            70      89\n",
       "4        language models            43            67      56\n",
       "5       dataset analysis            42            51      21"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fetch_trends_data(q, history_start='7-d', data_type=None):\n",
    "\t# https://serpapi.com/google-trends-api\n",
    "\tnow = 'now' if history_start[-1] == 'd' else 'today'\n",
    "\tquery = { 'q': [q], 'engine': trends_engine,\n",
    "\t\t\t 'date': f'{now} {history_start}'}\n",
    "\tif data_type:\n",
    "\t\tquery['data_type'] = data_type\n",
    "\tsearch = SerpApiClient(query)\n",
    "\tsearch.SERP_API_KEY = os.getenv('SERP_API_KEY')\n",
    "\tsearch = search.get_dict()\n",
    "\tif 'error' in search and 'out of searches' in search['error']:\n",
    "\t\tprint_error()\n",
    "\t\traise Exception(search['error'])\n",
    "\treturn search\n",
    "\n",
    "get_value = lambda x: x['values'][0]['extracted_value']\n",
    "\n",
    "data_list = []\n",
    "for keyword in keywords:\n",
    "\ttrend_data = fetch_trends_data(keyword)\n",
    "\tif 'error' in trend_data:\n",
    "\t\tprint_error()\n",
    "\t\tif 'out of searches' in trend_data['error']:\n",
    "\t\t\tbreak\n",
    "\t\tif 'hasn\\'t returned any results' in trend_data['error']:\n",
    "\t\t\tcontinue\n",
    "\t\tif not len(data_list):  # first case got failed, so stop now\n",
    "\t\t\tprint(trend_data['error'])\n",
    "\t\t\tbreak\n",
    "\t\tcontinue\n",
    "\tdata = trend_data['interest_over_time']['timeline_data']\n",
    "\toldest_value = get_value(data[0]) or 1\n",
    "\tlatest_value = get_value(data[-1]) or get_value(data[-2])\n",
    "\tgrowth = round(((latest_value - oldest_value) / oldest_value) * 100)\n",
    "\tdata_list.append([keyword, oldest_value, latest_value, growth])\n",
    "\tprint_progress()\n",
    "\n",
    "df_7d = pd.DataFrame(data_list, columns=['Keyword', 'Oldest_Value',\n",
    "\t\t\t\t\t\t\t\t\t\t'Latest_Value', 'Growth'])\n",
    "df_7d.sort_values(by=['Growth', 'Latest_Value', 'Oldest_Value'],\n",
    "\t\t\t\t\tascending=False, inplace=True)\n",
    "df_7d = df_7d[df_7d['Latest_Value'] > 0]  # remove if latest value is 0\n",
    "df_7d.reset_index(drop=True, inplace=True)\n",
    "df_7d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. \tGenerated long-tail keywords and their trend data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 5 long-tail keywords:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['language models for data prediction',\n",
       " 'language models for machine learning applications',\n",
       " 'training language models on small datasets',\n",
       " 'language models for data augmentation techniques',\n",
       " 'using language models for predictive analytics']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take top trendy keywords from both dfs and generate long keywords\n",
    "top_n = 10\n",
    "top_short_keywords = set(df_7d['Keyword'].head(top_n).tolist())\n",
    "\n",
    "# Generate long-tail keywords from top short-tail keywords\n",
    "long_kw_prompt_template = '''\n",
    "Top trending short-tail SEO keywords:\n",
    "`{top_short_keywords}`\n",
    "---\n",
    "Topic: `{page_title}`\n",
    "\n",
    "Generate 5 long-tail SEO keywords for each of the top trending short-tail keywords.\n",
    "Generate those that might have more demand.\n",
    "Respond with a list of long-tail SEO keywords separated by commas, inside tags like this:\n",
    "Sample response:\n",
    "<keywords>\n",
    "\tkeyword1, keyword2, keyword3\n",
    "</keywords>\n",
    "'''.strip()\n",
    "\n",
    "long_kw_prompt = long_kw_prompt_template.format(page_title=page_title,\n",
    "\t\t\t\t\ttop_short_keywords=', '.join(top_short_keywords))\n",
    "long_kw_response = get_lm_response(long_kw_prompt)\n",
    "long_keywords = extract_data(long_kw_response, tag='keywords')\n",
    "long_keywords = long_keywords.split(',')\n",
    "long_keywords = [keyword.strip() for keyword in long_keywords]\n",
    "long_keywords = [keyword.lower() for keyword in long_keywords]\n",
    "long_keywords = long_keywords[:5]  # take only first few\n",
    "print(f'Generated {len(long_keywords)} long-tail keywords:')\n",
    "long_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".,..."
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Oldest_Value</th>\n",
       "      <th>Latest_Value</th>\n",
       "      <th>Growth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>language models for data prediction</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>training language models on small datasets</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>language models for data augmentation techniques</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>using language models for predictive analytics</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Keyword  Oldest_Value  \\\n",
       "0               language models for data prediction             1   \n",
       "1        training language models on small datasets             1   \n",
       "2  language models for data augmentation techniques             1   \n",
       "3    using language models for predictive analytics             1   \n",
       "\n",
       "   Latest_Value  Growth  \n",
       "0             0    -100  \n",
       "1             0    -100  \n",
       "2             0    -100  \n",
       "3             0    -100  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list = []\n",
    "for keyword in long_keywords:\n",
    "\ttrend_data = fetch_trends_data(keyword)\n",
    "\tif 'error' in trend_data:\n",
    "\t\tif 'hasn\\'t returned any results' in trend_data['error']:\n",
    "\t\t\tprint_progress(',')\n",
    "\t\t\tcontinue\n",
    "\t\tprint_error()\n",
    "\t\tif not len(data_list):\n",
    "\t\t\tbreak\n",
    "\t\tcontinue\n",
    "\tdata = trend_data['interest_over_time']['timeline_data']\n",
    "\toldest_value = get_value(data[0]) or 1\n",
    "\tlatest_value = get_value(data[-1]) or get_value(data[-2]) or get_value(data[-3])\n",
    "\tgrowth = round(((latest_value - oldest_value) / oldest_value) * 100)\n",
    "\tdata_list.append([keyword, oldest_value, latest_value, growth])\n",
    "\tprint_progress()\n",
    "\n",
    "df_long_7d = pd.DataFrame(data_list, columns=['Keyword', 'Oldest_Value',\n",
    "\t\t\t\t\t\t\t\t\t\t'Latest_Value', 'Growth'])\n",
    "df_long_7d.sort_values(by=['Growth', 'Latest_Value', 'Oldest_Value'],\n",
    "\t\t\t\t\tascending=False, inplace=True)\n",
    "# df_long_7d = df_long_7d[df_long_7d['Latest_Value'] > 0]\n",
    "df_long_7d.reset_index(drop=True, inplace=True)\n",
    "df_long_7d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing keywords with 0 latest value:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Oldest_Value</th>\n",
       "      <th>Latest_Value</th>\n",
       "      <th>Growth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Keyword, Oldest_Value, Latest_Value, Growth]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('After removing keywords with 0 latest value:')\n",
    "df_long_7d = df_long_7d[df_long_7d['Latest_Value'] > 0]\n",
    "df_long_7d.reset_index(drop=True, inplace=True)\n",
    "df_long_7d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. \tGenerating a description for metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['language models',\n",
       " 'transparent ai',\n",
       " 'large language models',\n",
       " 'explainable ai',\n",
       " 'machine learning']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n_final = 5\n",
    "all_keywords = set()\n",
    "for df in [df_7d, df_long_7d]:  # df_1m, df_related, \n",
    "\tif df is not None:\n",
    "\t\tall_keywords.update(df['Keyword'].head(top_n_final).tolist())\n",
    "\n",
    "all_keywords = list(all_keywords)\n",
    "all_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'large language models transparent ai explainable ai machine learning'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combiner_prompt_template = '''\n",
    "Act as an SEO expert.\n",
    "Combine multiple keywords without altering their content.\n",
    "For example, \"A\" + \"A B\" + \"B\" + \"B C D\" -> \"A B C D\".\n",
    "For example, input: ['uses', 'uses of car',\n",
    "\t'cars', 'cars in the world', 'drive a car']\n",
    "output: <keywords>uses of cars in the world drive a car</keywords>\n",
    "\n",
    "Use the following SEO keywords as input:\n",
    "<keywords>{top_keywords}</keywords>\n",
    "\n",
    "**Important Rules**:\n",
    "1. Combine only the keywords provided. **Do not add new words**.\n",
    "2. **All input keywords** must be present in the output exactly as provided. Do not change, modify, or substitute them.\n",
    "3. Handle duplicates intelligently by removing redundancy (e.g., \"cars\" + \"cars in the world\" -> \"cars in the world\").\n",
    "4. The order of keywords can be flexible but should maintain logical flow and readability.\n",
    "5. The final output should not exceed the total number of characters of the original keywords combined.\n",
    "All the input keywords that must exist in the output keyword:\n",
    "<keywords>{top_keywords}</keywords>\n",
    "\n",
    "Respond with a single combined keyword inside tags like this:\n",
    "Sample response:\n",
    "<keywords>(keyword here)</keywords>\n",
    "'''.strip()\n",
    "\n",
    "combiner_prompt = combiner_prompt_template.format(\n",
    "\t\t\ttop_keywords=' \\n '.join(all_keywords))\n",
    "for _ in range(10):\n",
    "\ttry:\n",
    "\t\tcombiner_response = get_lm_response(combiner_prompt)\n",
    "\t\tcombined_keyword = extract_data(combiner_response, tag='keywords')\n",
    "\t\tcombined_keyword = combined_keyword.strip()\n",
    "\t\tfor keyword in all_keywords:\n",
    "\t\t\tif keyword not in combined_keyword:\n",
    "\t\t\t\tcombined_keyword = None\n",
    "\t\t\t\traise Exception(f'Error: {keyword} not found in combined keyword')\n",
    "\t\tif len(combined_keyword) > len(''.join(all_keywords)):\n",
    "\t\t\tprint('Words not reduced')\n",
    "\t\t\traise Exception('Extra words got added. Please try again.')\n",
    "\t\tall_combined_keywords_set = ' '.join(combined_keyword).split(' ')\n",
    "\t\tall_keywords_set = ' '.join(all_keywords)\n",
    "\t\tfor word in all_combined_keywords_set:\n",
    "\t\t\tif word not in all_keywords_set:\n",
    "\t\t\t\tprint('Extra words got added')\n",
    "\t\t\t\traise Exception('Extra words got added. Please try again.')\n",
    "\t\tbreak\n",
    "\texcept Exception as e:\n",
    "\t\tprint_error()\n",
    "\t\tif 'out of searches' in str(e):\n",
    "\t\t\tbreak\n",
    "\t\tcontinue\n",
    "combined_keyword"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. \tGenerating tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 10 tags:\n",
      "“Transparent AI”, “Explainable AI”, “Machine Learning”, “Large Language Models”, “Natural Language Processing”, “AI for Healthcare”, “Data Augmented Prediction”, “Interpretable AI”, “Artificial Intelligence”, “Language Model Learning”, "
     ]
    }
   ],
   "source": [
    "tags_prompt_template = '''\n",
    "Page content:\n",
    "{page_content}\n",
    "---\n",
    "Page title: {page_title}\n",
    "\n",
    "Generate in regular case. Tags need not be in lower case.\n",
    "Act as an SEO expert. Create a list of 10 most popular tags for the blog post.\n",
    "Respond with a list of tags separated by commas, inside tags like this:\n",
    "Sample response:\n",
    "<tags>\n",
    "\ttag1, tag2, tag3\n",
    "</tags>\n",
    "'''.strip()\n",
    "tags_prompt = tags_prompt_template.format(\n",
    "\tpage_content=page_content, combined_keyword=combined_keyword,\n",
    "\tpage_title=page_title)\n",
    "tags_response = get_lm_response(tags_prompt)\n",
    "tags = extract_data(tags_response, tag='tags')\n",
    "tags = tags.split(',')\n",
    "tags = [tag.strip() for tag in tags]\n",
    "tags = tags[:10]  # take only first few\n",
    "print(f'Generated {len(tags)} tags:')\n",
    "for tag in tags:\n",
    "\tprint(f'“{tag}”, ', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....,,...."
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>Oldest_Value</th>\n",
       "      <th>Latest_Value</th>\n",
       "      <th>Growth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AI Model Explainability</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>9900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>51</td>\n",
       "      <td>72</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Language Model Learning</td>\n",
       "      <td>46</td>\n",
       "      <td>65</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Large Language Models</td>\n",
       "      <td>44</td>\n",
       "      <td>58</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Explainable AI</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AI Predictions</td>\n",
       "      <td>42</td>\n",
       "      <td>48</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Transparent AI</td>\n",
       "      <td>57</td>\n",
       "      <td>64</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Tag  Oldest_Value  Latest_Value  Growth\n",
       "0  AI Model Explainability             1           100    9900\n",
       "1         Machine Learning            51            72      41\n",
       "2  Language Model Learning            46            65      41\n",
       "3    Large Language Models            44            58      32\n",
       "4           Explainable AI            40            50      25\n",
       "5           AI Predictions            42            48      14\n",
       "6           Transparent AI            57            64      12"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the most trending tags\n",
    "tags_data = []\n",
    "for tag in tags:\n",
    "\ttrend_data = fetch_trends_data(tag)\n",
    "\tif 'error' in trend_data:\n",
    "\t\tif 'hasn\\'t returned any results' in trend_data['error']:\n",
    "\t\t\tprint_progress(',')\n",
    "\t\t\tcontinue\n",
    "\t\tprint_error()\n",
    "\t\tif not len(tags_data):\n",
    "\t\t\tbreak\n",
    "\t\tcontinue\n",
    "\tdata = trend_data['interest_over_time']['timeline_data']\n",
    "\toldest_value = get_value(data[0]) or 1\n",
    "\tlatest_value = get_value(data[-1]) or get_value(data[-2]) or get_value(data[-3])\n",
    "\tgrowth = round(((latest_value - oldest_value) / oldest_value) * 100)\n",
    "\ttags_data.append([tag, oldest_value, latest_value, growth])\n",
    "\tprint_progress()\n",
    "\n",
    "df_tags = pd.DataFrame(tags_data, columns=['Tag', 'Oldest_Value',\n",
    "\t\t\t\t\t\t\t\t\t\t'Latest_Value', 'Growth'])\n",
    "df_tags.sort_values(by=['Growth', 'Latest_Value', 'Oldest_Value'],\n",
    "\t\t\t\t\tascending=False, inplace=True)\n",
    "df_tags = df_tags[df_tags['Latest_Value'] > 0]\n",
    "df_tags.reset_index(drop=True, inplace=True)\n",
    "df_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5 trending tags:\n",
      "“AI Model Explainability”, “Machine Learning”, “Language Model Learning”, “Large Language Models”, “Explainable AI”, "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>Oldest_Value</th>\n",
       "      <th>Latest_Value</th>\n",
       "      <th>Growth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AI Model Explainability</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>9900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>51</td>\n",
       "      <td>72</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Language Model Learning</td>\n",
       "      <td>46</td>\n",
       "      <td>65</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Large Language Models</td>\n",
       "      <td>44</td>\n",
       "      <td>58</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Explainable AI</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Tag  Oldest_Value  Latest_Value  Growth\n",
       "0  AI Model Explainability             1           100    9900\n",
       "1         Machine Learning            51            72      41\n",
       "2  Language Model Learning            46            65      41\n",
       "3    Large Language Models            44            58      32\n",
       "4           Explainable AI            40            50      25"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "used_tags = df_tags.head(5)  # take only top 5 tags\n",
    "trending_tags = used_tags['Tag'].tolist()\n",
    "print(f'There are {len(trending_tags)} trending tags:')\n",
    "for tag in trending_tags:\n",
    "\tprint(f'“{tag}”, ', end='')\n",
    "\n",
    "used_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'large language models transparent ai explainable ai machine learning AI Model Explainability Machine Learning Language Model Learning Large Language Models Explainable AI'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding tags to combined_keyword until it reaches 160 characters\n",
    "for tag in trending_tags:\n",
    "\tif tag not in combined_keyword:\n",
    "\t\tcombined_keyword += f' {tag}'\n",
    "combined_keyword"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Generating a title for SEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEO title: Introducing LML-DAP: A New Way to Combine Language Models with Data for Better, Explainable Predictions\n"
     ]
    }
   ],
   "source": [
    "seo_title_prompt_template = '''\n",
    "Page content:\n",
    "{page_content}\n",
    "---\n",
    "SEO keywords:\n",
    "`{keywords}`\n",
    "Page title: {page_title}\n",
    "\n",
    "Generate an SEO title for the blog post based on the keywords.\n",
    "Respond with the title inside tags like this:\n",
    "Sample response:\n",
    "<title>(title here)</title>\n",
    "'''.strip()\n",
    "seo_title_prompt = seo_title_prompt_template.format(\n",
    "\tpage_content=page_content, keywords=', '.join(all_keywords),\n",
    "\tpage_title=page_title)\n",
    "seo_title_response = get_lm_response(seo_title_prompt)\n",
    "seo_title = extract_data(seo_title_response, tag='title')\n",
    "seo_title = seo_title.strip()\n",
    "print(f'SEO title: {seo_title}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Usage of the keywords in the tags of the HTML page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_meta_tags = '''\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "\t<title>{seo_title}</title>\n",
    "\t<meta charset=\"UTF-8\">\n",
    "\t<meta property=\"og:title\" content=\"{seo_title}\">\n",
    "\t<meta name=\"description\" content=\"{seo_description}\">\n",
    "\t<meta property=\"og:description\" content=\"{seo_description}\">\n",
    "\t<meta name=\"keywords\" content=\"{keywords}\">\n",
    "\t<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "</head>\n",
    "<body>\n",
    "<!-- hidden tags are not supported on Medium.com -->\n",
    "<!-- <h1 style=\"display: none;\">{combined_keyword}</h1> -->\n",
    "\n",
    "<h1>{page_title}</h1>\n",
    "\n",
    "{page_content}\n",
    "\n",
    "Keywords: {combined_keyword}\n",
    "</body>\n",
    "</html>\n",
    "'''.lstrip()\n",
    "html_content = html_meta_tags.format(\n",
    "\tseo_title=seo_title, page_title=page_title, keywords=', '.join(all_keywords),\n",
    "\tseo_description=f'Content on {combined_keyword}'[:155],\n",
    "\tcombined_keyword=combined_keyword,\n",
    "\tpage_content=markdown2.markdown(page_content),  # md to html\n",
    ")\n",
    "\n",
    "html_file = os.path.join(data_folder, f'{topic_for_url}.html')\n",
    "with open(html_file, 'w') as f:\n",
    "\tf.write(html_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata loaded from json file\n"
     ]
    }
   ],
   "source": [
    "# save in metadata_file as backup\n",
    "metadata = {\n",
    "\t'topic': topic,\n",
    "\t'page_title': page_title,\n",
    "\t'all_keywords': all_keywords,\n",
    "\t'combined_keyword': combined_keyword,\n",
    "\t'trending_tags': trending_tags,\n",
    "}\n",
    "with open(metadata_file, 'w', encoding='utf-8') as f:\n",
    "\tjson.dump(metadata, f, indent=4)\n",
    "\tprint(f'Metadata saved in json file')\n",
    "\n",
    "# to load from metadata_file anytime\n",
    "with open(metadata_file, 'r', encoding='utf-8') as f:\n",
    "\tmetadata = json.load(f)\n",
    "\ttopics = metadata['topic']\n",
    "\tpage_title = metadata['page_title']\n",
    "\tall_keywords = metadata['all_keywords']\n",
    "\tcombined_keyword = metadata['combined_keyword']\n",
    "\ttrending_tags = metadata['trending_tags']\n",
    "\tprint('Metadata loaded from json file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Generating paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/explainable-ai-predictions', '/lml-dap-alternative-ml']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alias_prompt_template = '''\n",
    "Page content:\n",
    "{page_content}\n",
    "---\n",
    "SEO keywords: `{keywords}`\n",
    "Page title: {page_title}\n",
    "Example path: /benefits-of-apples/\n",
    "\n",
    "Generate meaningful paths for the blog post.\n",
    "A path must have the least possible number of words (max 4).\n",
    "\n",
    "Return a list of 2 paths line-by-line, inside tags like this:\n",
    "Sample response:\n",
    "<paths>\n",
    "\t/alias1 \\n /alias2\n",
    "</paths>\n",
    "'''.strip()\n",
    "alias_prompt = alias_prompt_template.format(\n",
    "\ttopic=topic, page_title=page_title, page_content=page_content,\n",
    "\tkeywords=', '.join(all_keywords))\n",
    "alias_response = get_lm_response(alias_prompt)\n",
    "url_paths = extract_data(alias_response, tag='paths')\n",
    "url_paths = url_paths.split('\\n')\n",
    "url_paths = [path.strip() for path in url_paths]\n",
    "url_paths"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
